# Modeling Stage - Student Retention Prediction

Este documento describe la implementaciÃ³n de la etapa de modelado para el proyecto de predicciÃ³n de retenciÃ³n estudiantil siguiendo la metodologÃ­a CRISP-DM.

## ğŸ“‹ DescripciÃ³n General

La etapa de modelado incluye:
- **Preprocesamiento**: IngenierÃ­a de caracterÃ­sticas y preparaciÃ³n de datos
- **Modelos Baseline**: RegresiÃ³n LogÃ­stica y Random Forest
- **Modelo Final**: Red Neuronal MLP (Multilayer Perceptron)
- **EvaluaciÃ³n**: MÃ©tricas comprehensivas y visualizaciones

## ğŸ—ï¸ Arquitectura del Proyecto

```
src/nombre_paquete/
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ feature_engineering.py    # IngenierÃ­a de caracterÃ­sticas
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline_model.py         # Modelos baseline
â”‚   â””â”€â”€ neural_network.py         # Modelo final MLP
â””â”€â”€ evaluation/
    â””â”€â”€ model_evaluator.py        # EvaluaciÃ³n de modelos

scripts/
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ main.py                   # Script de preprocesamiento
â”œâ”€â”€ training/
â”‚   â””â”€â”€ main.py                   # Script de entrenamiento
â””â”€â”€ evaluation/
    â””â”€â”€ main.py                   # Script de evaluaciÃ³n
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Instalar Dependencias

```bash
pip install -r requirements_modeling.txt
```

### 2. Verificar Datos Procesados

AsegÃºrate de que los siguientes archivos estÃ©n disponibles en `data/processed/`:
- `student_consolidated.csv` o `student_info_clean.csv`
- `interaction_features.csv` (opcional)

## ğŸ“Š Flujo de Trabajo

### Paso 1: Preprocesamiento

```bash
cd scripts/preprocessing
python main.py
```

**Resultados esperados:**
- `data/processed/modeling_features.csv`
- `data/processed/modeling_target.csv`
- `data/processed/feature_importance_ranking.csv`
- `data/processed/feature_info.json`

### Paso 2: Entrenamiento

```bash
cd scripts/training
python main.py
```

**Resultados esperados:**
- `models/logistic_regression_model.pkl`
- `models/random_forest_model.pkl`
- `models/neural_network_model.pkl`
- `data/processed/training_results.json`
- `docs/modeling/plots/neural_network_training_history.png`

### Paso 3: EvaluaciÃ³n

```bash
cd scripts/evaluation
python main.py
```

**Resultados esperados:**
- `data/processed/evaluation_results.json`
- `data/processed/final_model_comparison.csv`
- `data/processed/evaluation_summary.json`
- `docs/modeling/plots/` (grÃ¡ficos de evaluaciÃ³n)

## ğŸ”§ Componentes Principales

### Feature Engineering (`src/nombre_paquete/preprocessing/feature_engineering.py`)

**Clase**: `FeatureEngineer`

**Funcionalidades:**
- CreaciÃ³n de caracterÃ­sticas demogrÃ¡ficas (one-hot encoding)
- IngenierÃ­a de caracterÃ­sticas acadÃ©micas
- IntegraciÃ³n de caracterÃ­sticas comportamentales
- PreparaciÃ³n de variable objetivo binaria

**Uso:**
```python
from nombre_paquete.preprocessing.feature_engineering import FeatureEngineer

engineer = FeatureEngineer()
features_df, target = engineer.prepare_features(student_df, interaction_df)
```

### Baseline Models (`src/nombre_paquete/models/baseline_model.py`)

**Clase**: `BaselineModel`

**Modelos disponibles:**
- `logistic`: RegresiÃ³n LogÃ­stica
- `random_forest`: Random Forest

**Uso:**
```python
from nombre_paquete.models.baseline_model import BaselineModel

# RegresiÃ³n LogÃ­stica
lr_model = BaselineModel(model_type='logistic')
metrics = lr_model.train(features_df, target)

# Random Forest
rf_model = BaselineModel(model_type='random_forest')
metrics = rf_model.train(features_df, target)
```

### Neural Network (`src/nombre_paquete/models/neural_network.py`)

**Clase**: `NeuralNetworkModel`

**Arquitectura por defecto:**
- Input: n_features
- Dense(128) + ReLU + Dropout(0.3) + BatchNorm
- Dense(64) + ReLU + Dropout(0.2) + BatchNorm
- Dense(32) + ReLU + Dropout(0.2) + BatchNorm
- Dense(1) + Sigmoid

**Uso:**
```python
from nombre_paquete.models.neural_network import NeuralNetworkModel

nn_model = NeuralNetworkModel(input_dim=len(features_df.columns))
metrics = nn_model.train(features_df, target, epochs=100)
```

### Model Evaluator (`src/nombre_paquete/evaluation/model_evaluator.py`)

**Clase**: `ModelEvaluator`

**Funcionalidades:**
- CÃ¡lculo de mÃ©tricas (F1, ROC-AUC, Precision, Recall)
- GeneraciÃ³n de grÃ¡ficos (matriz de confusiÃ³n, ROC, Precision-Recall)
- ComparaciÃ³n de modelos
- Reportes de evaluaciÃ³n

**Uso:**
```python
from nombre_paquete.evaluation.model_evaluator import ModelEvaluator

evaluator = ModelEvaluator()
report = evaluator.generate_evaluation_report(y_true, y_pred, y_pred_proba, 'model_name')
```

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

### MÃ©tricas Principales
- **F1-Score**: Objetivo â‰¥ 85%
- **ROC-AUC**: Ãrea bajo la curva ROC
- **Precision**: ProporciÃ³n de predicciones positivas correctas
- **Recall**: ProporciÃ³n de casos positivos identificados
- **Accuracy**: ProporciÃ³n total de predicciones correctas

### InterpretaciÃ³n
- **F1-Score â‰¥ 85%**: Excelente capacidad de clasificaciÃ³n
- **ROC-AUC â‰¥ 0.85**: Excelente capacidad discriminativa
- **Precision â‰¥ 0.80**: Baja tasa de falsos positivos
- **Recall â‰¥ 0.80**: Baja tasa de falsos negativos

## ğŸ“Š Visualizaciones Generadas

### Durante el Entrenamiento
- **Historial de entrenamiento**: Loss, accuracy, precision, recall vs Ã©pocas
- **GrÃ¡ficos de convergencia**: Para el modelo de red neuronal

### Durante la EvaluaciÃ³n
- **Matriz de confusiÃ³n**: Para cada modelo
- **Curva ROC**: Para cada modelo
- **Curva Precision-Recall**: Para cada modelo
- **Importancia de caracterÃ­sticas**: Top caracterÃ­sticas mÃ¡s relevantes
- **ComparaciÃ³n de modelos**: GrÃ¡fico de barras con mÃ©tricas

## ğŸ” Interpretabilidad

### CaracterÃ­sticas MÃ¡s Importantes
1. **NÃºmero de intentos previos**: Indicador fuerte de riesgo
2. **Banda socioeconÃ³mica**: Factor contextual importante
3. **Actividad en plataforma**: Indicador de compromiso
4. **Fecha de desmatrÃ­cula**: Indicador directo de abandono
5. **Nivel educativo previo**: Factor de preparaciÃ³n acadÃ©mica

### TÃ©cnicas de InterpretaciÃ³n
- **SHAP Values**: Para explicaciÃ³n de predicciones individuales
- **Feature Importance**: Para modelos baseline
- **Correlation Analysis**: Para entender relaciones lineales

## ğŸ¯ Objetivos del Proyecto

### Criterios de Ã‰xito
- âœ… **F1-Score â‰¥ 85%**: Capacidad de clasificaciÃ³n confiable
- âœ… **Pipeline automatizado**: Proceso reproducible y escalable
- âœ… **CÃ³digo documentado**: Notebooks y scripts claros
- âœ… **Interpretabilidad**: ExplicaciÃ³n de predicciones

### MetodologÃ­a
- **CRISP-DM**: Cross-Industry Standard Process for Data Mining
- **Agile**: Iteraciones breves con entregables especÃ­ficos
- **Deep Learning**: TensorFlow/Keras para modelo final

## ğŸ“ Estructura de Archivos

### Entrada
```
data/processed/
â”œâ”€â”€ student_consolidated.csv      # Datos de estudiantes
â”œâ”€â”€ interaction_features.csv       # CaracterÃ­sticas de interacciones
â””â”€â”€ assessment_features.csv        # CaracterÃ­sticas de evaluaciones
```

### Salida
```
data/processed/
â”œâ”€â”€ modeling_features.csv          # CaracterÃ­sticas para modelado
â”œâ”€â”€ modeling_target.csv            # Variable objetivo
â”œâ”€â”€ feature_importance_ranking.csv # Ranking de importancia
â”œâ”€â”€ training_results.json          # Resultados de entrenamiento
â”œâ”€â”€ evaluation_results.json        # Resultados de evaluaciÃ³n
â””â”€â”€ final_model_comparison.csv     # ComparaciÃ³n final

models/
â”œâ”€â”€ logistic_regression_model.pkl  # Modelo baseline 1
â”œâ”€â”€ random_forest_model.pkl        # Modelo baseline 2
â””â”€â”€ neural_network_model.pkl       # Modelo final

docs/modeling/plots/
â”œâ”€â”€ neural_network_training_history.png
â”œâ”€â”€ logistic_regression_confusion_matrix.png
â”œâ”€â”€ random_forest_roc_curve.png
â””â”€â”€ final_model_comparison.png
```

## ğŸš¨ Troubleshooting

### Problemas Comunes

1. **Error: "No se encontraron archivos de datos"**
   - Verifica que los archivos estÃ©n en `data/processed/`
   - Ejecuta primero el script de preprocesamiento

2. **Error: "TensorFlow no disponible"**
   - Instala TensorFlow: `pip install tensorflow`
   - Verifica la versiÃ³n de Python (3.8+)

3. **Error: "Memoria insuficiente"**
   - Reduce el tamaÃ±o del batch en el modelo neural
   - Usa menos caracterÃ­sticas o menos datos

4. **Error: "Modelo no converge"**
   - Ajusta el learning rate
   - Aumenta el nÃºmero de Ã©pocas
   - Verifica la calidad de los datos

### Logs y Debugging
- Todos los scripts generan logs detallados
- Revisa los archivos de log para identificar problemas
- Usa `logging.basicConfig(level=logging.DEBUG)` para mÃ¡s detalles

## ğŸ“š Referencias

- **Dataset**: Open University Learning Analytics Dataset (OULAD)
- **MetodologÃ­a**: CRISP-DM (Cross-Industry Standard Process)
- **Deep Learning**: TensorFlow/Keras Documentation
- **Interpretabilidad**: SHAP (SHapley Additive exPlanations)

## ğŸ¤ ContribuciÃ³n

Para contribuir al proyecto:
1. Sigue la estructura de archivos existente
2. Documenta nuevas funcionalidades
3. MantÃ©n compatibilidad con el pipeline existente
4. Ejecuta todos los tests antes de commit

---

**Nota**: Este proyecto sigue la metodologÃ­a CRISP-DM y estÃ¡ diseÃ±ado para ser reproducible y escalable en diferentes contextos educativos. 